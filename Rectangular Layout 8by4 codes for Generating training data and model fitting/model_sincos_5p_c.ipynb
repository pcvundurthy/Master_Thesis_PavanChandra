{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner.tuners import RandomSearch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the Training data (virtually generated) from a file \n",
    "#Input data\n",
    "x_data = pd.read_csv('x_rec_16_data_5.csv')\n",
    "x_data=x_data.values[:,1:]\n",
    "print(\"read_x_data\")\n",
    "#Output data\n",
    "y_data = pd.read_csv('y_rec_16_data_5.csv')\n",
    "y_data=y_data.values[:,1:]\n",
    "print(\"read_y_data\")\n",
    "print(x_data[:2,:])\n",
    "print(y_data[:2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(x_data, y_data)\n",
    "print(np.shape(X_train), np.shape(y_train), \"training data size\")\n",
    "print(np.shape(X_val), np.shape(y_val),\"Validation data size\")\n",
    "#print(X_train[0:9,:])\n",
    "\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "scaler_x.fit(X_train)\n",
    "xtrain_scale=scaler_x.transform(X_train)\n",
    "\n",
    "scaler_x.fit(X_val)\n",
    "xval_scale=scaler_x.transform(X_val)\n",
    "\n",
    "scaler_y.fit(y_train)\n",
    "ytrain_scale=scaler_y.transform(y_train)\n",
    "\n",
    "scaler_y.fit(y_val)\n",
    "yval_scale=scaler_y.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from numpy import loadtxt\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "input_layer = Input(shape=(48,))\n",
    "hidden_layer_1 = Dense(units = 700, activation = 'relu')(input_layer)\n",
    "hidden_layer_2 = Dense(units = 700, activation = 'relu')(hidden_layer_1)\n",
    "output_layer = Dense(units = 7, activation = 'linear')(hidden_layer_2)\n",
    "model = Model(inputs = input_layer, outputs = output_layer, name = 'sensor_concept_nn')\n",
    "#opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(loss='mse', optimizer=opt)\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 5:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "# Display the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(xtrain_scale, ytrain_scale, epochs=30, verbose=2, validation_data=(xval_scale,yval_scale),callbacks=[callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "#plt.ylim(0.07,0.15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "f = open('loss_vs_val_loss.txt','w')\n",
    "f.write(history.history['loss'])\n",
    "f.write(history.history['val_loss'])\n",
    "f.write('end')\n",
    "# do this as long as you need to\n",
    "f.seek(0,0) # return to the beginning of the file if you need to\n",
    "f.close() # close the file handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creating a Callback subclass that stores each epoch prediction\n",
    "class prediction_history(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        self.predhis = []\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.predhis.append(model.predict(xval_scale))\n",
    "\n",
    "#Calling the subclass\n",
    "predictions=prediction_history()\n",
    "\n",
    "#Executing the model.fit of the neural network\n",
    "#model.fit(X=predictor_train, y=target_train, nb_epoch=2, batch_size=batch,validation_split=0.1,callbacks=[predictions]) \n",
    "history = model.fit(xtrain_scale, ytrain_scale, epochs=30, verbose=2, validation_data=(xval_scale,yval_scale),callbacks=[callback,predictions])\n",
    "#Printing the prediction history\n",
    "#print (predictions.predhis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_data=predictions.predhis\n",
    "np.shape(check_data)\n",
    "err_sincos_mean=[]\n",
    "\n",
    "for i in range(0,20):\n",
    "    err_sincos = (check_data[i][:][2]**2+check_data[i][:][3]**2)-1\n",
    "    err_sincos_mean.append(np.mean(err_sincos))\n",
    "print(err_sincos_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.plot(err_sincos_mean)\n",
    "plt.title('Model Loss with sincos')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val','sincos'], loc='upper left')\n",
    "#plt.ylim(0.07,0.15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd = np.array(history.history['val_loss'])\n",
    "print(asd)\n",
    "\n",
    "plt.plot(asd)\n",
    "plt.plot(err_sincos_mean)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,sharex=True)\n",
    "fig.suptitle('Validation Loss vs. Error in Sin and Cos predictions ')\n",
    "axs[0].plot(asd)\n",
    "axs[1].plot(err_sincos_mean)\n",
    "ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(asd/err_sincos_mean)\n",
    "plt.ylim(-0.5,0.5)\n",
    "plt.show()\n",
    "print(np.mean(asd/err_sincos_mean))\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('error in Sin and Cos prediction')\n",
    "plt.title('epochs vs. prediction error in Sin and Cos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### err_sincos_mean is sin**2(beta)+cos**2(beat)-1\n",
    "### asd is validation loss of the model\n",
    "\n",
    "# asd = constant * err_sincos_mean\n",
    "\n",
    "### the constant in this case is -0.2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
